{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrederickUdis/fundamentosSparkDataFrames/blob/main/FundamentosSparkDataFrames.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRThDiA6Anr-"
      },
      "source": [
        "# Fundamentos de Apache Spark: SQL/DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kVyn2yVAnsB"
      },
      "source": [
        "**Spark** SQL opera con **DataFrames**. Un **DataFrame** es una visualización relacional de la información. Ofrece funciones con características parecidas a SQL. También, posibilita redactar interrogantes al estilo SQL para nuestra exploración de datos.\n",
        "\n",
        "Los **DataFrames** se asemejan a las tablas relacionales o a los DataFrames en Python/R, aunque con numerosas mejoras que se llevan a cabo de forma \"transparente\" para el usuario. Existen múltiples métodos para generar DataFrames desde conjuntos, tablas HIVE, tablas relacionales y RDD."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "configuracion del entorno para instalar java"
      ],
      "metadata": {
        "id": "qr55zWEb679L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "id": "HLz1Qrk45STv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://dlcdn.apache.org/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz\n",
        "!tar xf spark-3.4.1-bin-hadoop3.tgz\n"
      ],
      "metadata": {
        "id": "h0Ku-WY77CZ1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalacion de la libreria findspark"
      ],
      "metadata": {
        "id": "9kONo_NlIr9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "4YSiQJBQIGti"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "importacion de findspark y creacion de la sesion"
      ],
      "metadata": {
        "id": "iqjTJSjc7Vfj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fw4yoCmhAnsC"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init(\"spark-3.4.1-bin-hadoop3\") # Asegúrate de que la versión coincida con la que descargaste\n",
        "import pandas as pd\n",
        "import pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rZDaVrv6AnsD"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSBRZQ_4AnsD"
      },
      "source": [
        "### Crear la sesión de Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5uoQdWqOAnsD"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXrkb26MAnsE"
      },
      "source": [
        "### Crear el DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wAqnE8FzAnsE"
      },
      "outputs": [],
      "source": [
        "emp = [(1, \"AAA\", \"dept1\", 1000),\n",
        "    (2, \"BBB\", \"dept1\", 1100),\n",
        "    (3, \"CCC\", \"dept1\", 3000),\n",
        "    (4, \"DDD\", \"dept1\", 1500),\n",
        "    (5, \"EEE\", \"dept2\", 8000),\n",
        "    (6, \"FFF\", \"dept2\", 7200),\n",
        "    (7, \"GGG\", \"dept3\", 7100),\n",
        "    (8, \"HHH\", \"dept3\", 3700),\n",
        "    (9, \"III\", \"dept3\", 4500),\n",
        "    (10, \"JJJ\", \"dept5\", 3400)]\n",
        "\n",
        "dept = [(\"dept1\", \"Department - 1\"),\n",
        "        (\"dept2\", \"Department - 2\"),\n",
        "        (\"dept3\", \"Department - 3\"),\n",
        "        (\"dept4\", \"Department - 4\")\n",
        "\n",
        "       ]\n",
        "\n",
        "df = spark.createDataFrame(emp, [\"id\", \"name\", \"dept\", \"salary\"])\n",
        "\n",
        "deptdf = spark.createDataFrame(dept, [\"id\", \"name\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bn3oQIxfAnsE",
        "outputId": "e5e04176-f494-4e3b-f70f-7db135ec79fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  1| AAA|dept1|  1000|\n",
            "|  2| BBB|dept1|  1100|\n",
            "|  3| CCC|dept1|  3000|\n",
            "|  4| DDD|dept1|  1500|\n",
            "|  5| EEE|dept2|  8000|\n",
            "|  6| FFF|dept2|  7200|\n",
            "|  7| GGG|dept3|  7100|\n",
            "|  8| HHH|dept3|  3700|\n",
            "|  9| III|dept3|  4500|\n",
            "| 10| JJJ|dept5|  3400|\n",
            "+---+----+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjyumsakAnsF"
      },
      "source": [
        "# Operaciones básicas en DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSMLDlDEAnsG"
      },
      "source": [
        "### count\n",
        "* Cuenta el número de filas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Yx_ihJzAnsG",
        "outputId": "2db06aab-1953-4bd4-fa58-c7cb2ad4dbf6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jo2RBRUAnsG"
      },
      "source": [
        "### columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl48-feuAnsG",
        "outputId": "b59f6c92-b635-4c44-c1aa-6292bf755080"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['id', 'name', 'dept', 'salary']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YFOweBLAnsH"
      },
      "source": [
        "### dtypes\n",
        "** Accede al DataType de columnas dentro del DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BovczhlSAnsH",
        "outputId": "c88dc9cf-f545-46eb-be67-5cb7c4d605b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('id', 'bigint'),\n",
              " ('name', 'string'),\n",
              " ('dept', 'string'),\n",
              " ('salary', 'bigint')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiKr5lw3AnsH"
      },
      "source": [
        "### schema\n",
        "** Comprueba cómo Spark almacena el esquema del DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay1nQB3vAnsH",
        "outputId": "18b643fb-4cd3-4478-d656-b408878c9981"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructType([StructField('id', LongType(), True), StructField('name', StringType(), True), StructField('dept', StringType(), True), StructField('salary', LongType(), True)])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df.schema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB41AAOBAnsH"
      },
      "source": [
        "### printSchema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yGlySSIAnsI",
        "outputId": "104fbfb2-b4f1-4cbb-a24d-eb18c4599898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- dept: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F9USFqjAnsI"
      },
      "source": [
        "### select\n",
        "* Seleccione columnas del DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIa1LmaGAnsI",
        "outputId": "113544aa-3d62-44d6-82fd-731fa4b54cf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+\n",
            "| id|name|\n",
            "+---+----+\n",
            "|  1| AAA|\n",
            "|  2| BBB|\n",
            "|  3| CCC|\n",
            "|  4| DDD|\n",
            "|  5| EEE|\n",
            "|  6| FFF|\n",
            "|  7| GGG|\n",
            "|  8| HHH|\n",
            "|  9| III|\n",
            "| 10| JJJ|\n",
            "+---+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select(\"id\", \"name\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIKfYoY0AnsI"
      },
      "source": [
        "### filter\n",
        "\n",
        "* Filtrar las filas según alguna condición.\n",
        "* Intentemos encontrar las filas con id = 1.\n",
        "* Hay diferentes formas de especificar la condición."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yL6kLkhAAnsI",
        "outputId": "b4ece60f-6115-4a6e-c28d-a6edb205e544"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  1| AAA|dept1|  1000|\n",
            "+---+----+-----+------+\n",
            "\n",
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  1| AAA|dept1|  1000|\n",
            "+---+----+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.filter(df[\"id\"] == 1).show()\n",
        "df.filter(df.id == 1).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omGzW4zVAnsJ",
        "outputId": "b686f7da-31f9-4d42-8665-cfe60aeb8277"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  1| AAA|dept1|  1000|\n",
            "+---+----+-----+------+\n",
            "\n",
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  1| AAA|dept1|  1000|\n",
            "+---+----+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.filter(col(\"id\") == 1).show()\n",
        "df.filter(\"id = 1\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ehJTlPzAnsJ"
      },
      "source": [
        "### drop\n",
        "* Elimina una columna en particular"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQnK9yA8AnsJ",
        "outputId": "6a4f84a1-155d-4cd4-e0ef-d8b5456e6ea1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+------+\n",
            "|name| dept|salary|\n",
            "+----+-----+------+\n",
            "| AAA|dept1|  1000|\n",
            "| BBB|dept1|  1100|\n",
            "+----+-----+------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "newdf = df.drop(\"id\")\n",
        "newdf.show(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf9h7Nn-AnsJ"
      },
      "source": [
        "### Aggregations\n",
        "* Podemos usar la función groupBy para agrupar los datos y luego usar la función \"agg\" para realizar la agregación de datos agrupados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83twCX-LAnsK",
        "outputId": "97fd1cb4-391c-4098-a9b2-ec1caba676f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----+----+----+------+\n",
            "| dept|count|  sum| max| min|   avg|\n",
            "+-----+-----+-----+----+----+------+\n",
            "|dept1|    4| 6600|3000|1000|1650.0|\n",
            "|dept2|    2|15200|8000|7200|7600.0|\n",
            "|dept5|    1| 3400|3400|3400|3400.0|\n",
            "|dept3|    3|15300|7100|3700|5100.0|\n",
            "+-----+-----+-----+----+----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "(df.groupBy(\"dept\")\n",
        "    .agg(\n",
        "        count(\"salary\").alias(\"count\"),\n",
        "        sum(\"salary\").alias(\"sum\"),\n",
        "        max(\"salary\").alias(\"max\"),\n",
        "        min(\"salary\").alias(\"min\"),\n",
        "        avg(\"salary\").alias(\"avg\")\n",
        "        ).show()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9EET8SdAnsK"
      },
      "source": [
        "### Sorting\n",
        "\n",
        "* Ordena los datos según el \"salario\". De forma predeterminada, la clasificación se realizará en orden ascendente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZj5rvojAnsK",
        "outputId": "c882d05b-0b62-40f3-93e0-0a03b41b4eeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  1| AAA|dept1|  1000|\n",
            "|  2| BBB|dept1|  1100|\n",
            "|  4| DDD|dept1|  1500|\n",
            "|  3| CCC|dept1|  3000|\n",
            "| 10| JJJ|dept5|  3400|\n",
            "+---+----+-----+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.sort(\"salary\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqDzDsMRAnsK",
        "outputId": "d9b96459-ee34-4ed8-80e1-2237d684f4bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  5| EEE|dept2|  8000|\n",
            "|  6| FFF|dept2|  7200|\n",
            "|  7| GGG|dept3|  7100|\n",
            "|  9| III|dept3|  4500|\n",
            "|  8| HHH|dept3|  3700|\n",
            "+---+----+-----+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Sort the data in descending order.\n",
        "df.sort(desc(\"salary\")).show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Oyq9J4jAnsK"
      },
      "source": [
        "### Columnas derivadas\n",
        "* Podemos usar la función \"withColumn\" para derivar la columna en función de las columnas existentes ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf6hcxt2AnsL",
        "outputId": "32e935d5-e7f2-42dc-8b2a-2cf38e60c670"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+-----+------+-----+\n",
            "| id|name| dept|salary|bonus|\n",
            "+---+----+-----+------+-----+\n",
            "|  1| AAA|dept1|  1000|100.0|\n",
            "|  2| BBB|dept1|  1100|110.0|\n",
            "|  3| CCC|dept1|  3000|300.0|\n",
            "|  4| DDD|dept1|  1500|150.0|\n",
            "|  5| EEE|dept2|  8000|800.0|\n",
            "|  6| FFF|dept2|  7200|720.0|\n",
            "|  7| GGG|dept3|  7100|710.0|\n",
            "|  8| HHH|dept3|  3700|370.0|\n",
            "|  9| III|dept3|  4500|450.0|\n",
            "| 10| JJJ|dept5|  3400|340.0|\n",
            "+---+----+-----+------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.withColumn(\"bonus\", col(\"salary\") * .1).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9jVwGfyAnsL"
      },
      "source": [
        "### Joins\n",
        "\n",
        "* Podemos realizar varios tipos de combinaciones en múltiples DataFrames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpgKzlhnAnsL",
        "outputId": "e3684533-cc5a-4f77-8eaf-ba2424543930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+-----+------+-----+--------------+\n",
            "| id|name| dept|salary|   id|          name|\n",
            "+---+----+-----+------+-----+--------------+\n",
            "|  1| AAA|dept1|  1000|dept1|Department - 1|\n",
            "|  2| BBB|dept1|  1100|dept1|Department - 1|\n",
            "|  3| CCC|dept1|  3000|dept1|Department - 1|\n",
            "|  4| DDD|dept1|  1500|dept1|Department - 1|\n",
            "|  5| EEE|dept2|  8000|dept2|Department - 2|\n",
            "|  6| FFF|dept2|  7200|dept2|Department - 2|\n",
            "|  7| GGG|dept3|  7100|dept3|Department - 3|\n",
            "|  8| HHH|dept3|  3700|dept3|Department - 3|\n",
            "|  9| III|dept3|  4500|dept3|Department - 3|\n",
            "+---+----+-----+------+-----+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Inner JOIN.\n",
        "df.join(deptdf, df[\"dept\"] == deptdf[\"id\"]).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02zrw0DsAnsM"
      },
      "source": [
        "### Left Outer Join"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7U_6f4RAnsX",
        "outputId": "24354fc9-4cc4-4b9b-cc9f-50c49bcd4c94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----+-----+------+-----+--------------+\n",
            "| id|name| dept|salary|   id|          name|\n",
            "+---+----+-----+------+-----+--------------+\n",
            "| 10| JJJ|dept5|  3400| null|          null|\n",
            "|  7| GGG|dept3|  7100|dept3|Department - 3|\n",
            "|  8| HHH|dept3|  3700|dept3|Department - 3|\n",
            "|  9| III|dept3|  4500|dept3|Department - 3|\n",
            "|  1| AAA|dept1|  1000|dept1|Department - 1|\n",
            "|  2| BBB|dept1|  1100|dept1|Department - 1|\n",
            "|  3| CCC|dept1|  3000|dept1|Department - 1|\n",
            "|  4| DDD|dept1|  1500|dept1|Department - 1|\n",
            "|  5| EEE|dept2|  8000|dept2|Department - 2|\n",
            "|  6| FFF|dept2|  7200|dept2|Department - 2|\n",
            "+---+----+-----+------+-----+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.join(deptdf, df[\"dept\"] == deptdf[\"id\"], \"left_outer\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C06NozkdAnsX"
      },
      "source": [
        "### Right Outer Join"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zX2o_dIMAnsX",
        "outputId": "84626e11-efb5-49e3-808e-48937534f0a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+----+-----+------+-----+--------------+\n",
            "|  id|name| dept|salary|   id|          name|\n",
            "+----+----+-----+------+-----+--------------+\n",
            "|   7| GGG|dept3|  7100|dept3|Department - 3|\n",
            "|   8| HHH|dept3|  3700|dept3|Department - 3|\n",
            "|   9| III|dept3|  4500|dept3|Department - 3|\n",
            "|   1| AAA|dept1|  1000|dept1|Department - 1|\n",
            "|   2| BBB|dept1|  1100|dept1|Department - 1|\n",
            "|   3| CCC|dept1|  3000|dept1|Department - 1|\n",
            "|   4| DDD|dept1|  1500|dept1|Department - 1|\n",
            "|null|null| null|  null|dept4|Department - 4|\n",
            "|   5| EEE|dept2|  8000|dept2|Department - 2|\n",
            "|   6| FFF|dept2|  7200|dept2|Department - 2|\n",
            "+----+----+-----+------+-----+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.join(deptdf, df[\"dept\"] == deptdf[\"id\"], \"right_outer\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8eBJiwOAnsX"
      },
      "source": [
        "### Full Outer Join"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unDltcxgAnsX",
        "outputId": "c126c945-9b02-4594-91bd-1201b4a419c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+----+-----+------+-----+--------------+\n",
            "|  id|name| dept|salary|   id|          name|\n",
            "+----+----+-----+------+-----+--------------+\n",
            "|  10| JJJ|dept5|  3400| null|          null|\n",
            "|   7| GGG|dept3|  7100|dept3|Department - 3|\n",
            "|   8| HHH|dept3|  3700|dept3|Department - 3|\n",
            "|   9| III|dept3|  4500|dept3|Department - 3|\n",
            "|   1| AAA|dept1|  1000|dept1|Department - 1|\n",
            "|   2| BBB|dept1|  1100|dept1|Department - 1|\n",
            "|   3| CCC|dept1|  3000|dept1|Department - 1|\n",
            "|   4| DDD|dept1|  1500|dept1|Department - 1|\n",
            "|null|null| null|  null|dept4|Department - 4|\n",
            "|   5| EEE|dept2|  8000|dept2|Department - 2|\n",
            "|   6| FFF|dept2|  7200|dept2|Department - 2|\n",
            "+----+----+-----+------+-----+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.join(deptdf, df[\"dept\"] == deptdf[\"id\"], \"outer\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlgDksGMAnsY"
      },
      "source": [
        "### Consultas SQL\n",
        "* Ejecución de consultas tipo SQL.\n",
        "* También podemos realizar análisis de datos escribiendo consultas similares a SQL. Para realizar consultas similares a SQL, necesitamos registrar el DataFrame como una Vista temporal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R636dWTJAnsY",
        "outputId": "bd6d26b1-1702-4133-a0c0-f85a2e90cd74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  1| AAA|dept1|  1000|\n",
            "+---+----+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Register DataFrame as Temporary Table\n",
        "df.createOrReplaceTempView(\"temp_table\")\n",
        "\n",
        "# Execute SQL-Like query.\n",
        "spark.sql(\"select * from temp_table where id = 1\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFc3JSVaAnsY",
        "outputId": "605719cf-b01b-4114-af6c-661aa1cf7ba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+\n",
            "| id|\n",
            "+---+\n",
            "|  7|\n",
            "|  6|\n",
            "|  9|\n",
            "|  5|\n",
            "|  1|\n",
            "| 10|\n",
            "|  3|\n",
            "|  8|\n",
            "|  2|\n",
            "|  4|\n",
            "+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"select distinct id from temp_table\").show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JwexTz5AnsY",
        "outputId": "ff6c3f88-bf46-4739-db8f-c27ba115a530"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----+-----+------+\n",
            "| id|name| dept|salary|\n",
            "+---+----+-----+------+\n",
            "|  3| CCC|dept1|  3000|\n",
            "|  4| DDD|dept1|  1500|\n",
            "|  5| EEE|dept2|  8000|\n",
            "|  6| FFF|dept2|  7200|\n",
            "|  7| GGG|dept3|  7100|\n",
            "|  8| HHH|dept3|  3700|\n",
            "|  9| III|dept3|  4500|\n",
            "| 10| JJJ|dept5|  3400|\n",
            "+---+----+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"select * from temp_table where salary >= 1500\").show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arjaeZ2-AnsZ"
      },
      "source": [
        "### Leyendo la tabla HIVE como DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIhzo5jIAnsZ"
      },
      "outputs": [],
      "source": [
        "# DB_NAME : Name of the the HIVE Database\n",
        "# TBL_NAME : Name of the HIVE Table\n",
        "\n",
        "\n",
        "df = spark.table(\"DB_NAME\".\"TBL_NAME\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRF1RJFPAnsZ"
      },
      "source": [
        "### Guardar DataFrame como tabla HIVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQ2AqYV2AnsZ"
      },
      "outputs": [],
      "source": [
        "df.write.saveAsTable(\"DB_NAME.TBL_NAME\")\n",
        "\n",
        "## También podemos seleccionar el argumento \"modo\" con overwrite\", \"append\", \"error\" etc.\n",
        "df.write.saveAsTable(\"DB_NAME.TBL_NAME\", mode=\"overwrite\")\n",
        "\n",
        "# De forma predeterminada, la operación guardará el DataFrame como una tabla interna / administrada de HIVE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYHY0ob6AnsZ"
      },
      "source": [
        "### Guardar el DataFrame como una tabla externa HIVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fds9-Y1aAnsa"
      },
      "outputs": [],
      "source": [
        "df.write.saveAsTable(\"DB_NAME.TBL_NAME\", path=<location_of_external_table>)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOVebTDZAnsa"
      },
      "source": [
        "### Crea un DataFrame a partir de un archivo CSV\n",
        "* Podemos crear un DataFrame usando un archivo CSV y podemos especificar varias opciones como un separador, encabezado, esquema, inferSchema y varias otras opciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvjS9P0fAnsa"
      },
      "outputs": [],
      "source": [
        " df = spark.read.csv(\"path_to_csv_file\", sep=\"|\", header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdQXP7R0Ansa"
      },
      "source": [
        "### Guardar un DataFrame como un archivo CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fI59MWcmAnsa"
      },
      "outputs": [],
      "source": [
        "df.write.csv(\"path_to_CSV_File\", sep=\"|\", header=True, mode=\"overwrite\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VAnRig4Ansb"
      },
      "source": [
        "### Crea un DataFrame a partir de una tabla relacional\n",
        "* Podemos leer los datos de bases de datos relacionales usando una URL JDBC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzo4wOGgAnsb"
      },
      "outputs": [],
      "source": [
        "# url : a JDBC URL of the form jdbc:subprotocol:subname\n",
        "# TBL_NAME : Name of the relational table.\n",
        "# USER_NAME : user name to connect to DataBase.\n",
        "# PASSWORD: password to connect to DataBase.\n",
        "\n",
        "\n",
        "relational_df = spark.read.format('jdbc')\n",
        "                        .options(url=url, dbtable= <TBL_NAME>, user= <USER_NAME>, password = <PASSWORD>)\n",
        "                        .load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-rb58RwAnsb"
      },
      "source": [
        "### Guardar el DataFrame como una tabla relacional\n",
        "* Podemos guardar el DataFrame como una tabla relacional usando una URL JDBC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0rGusJiAnsb"
      },
      "outputs": [],
      "source": [
        "# url : a JDBC URL of the form jdbc:subprotocol:subname\n",
        "# TBL_NAME : Name of the relational table.\n",
        "# USER_NAME : user name to connect to DataBase.\n",
        "# PASSWORD: password to connect to DataBase.\n",
        "\n",
        "\n",
        " relational_df.write.format('jdbc')\n",
        "                    .options(url=url, dbtable= <TBL_NAME>, user= <USER_NAME>, password = <PASSWORD>)\n",
        "                    .mode('overwrite')\n",
        "                    .save()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}